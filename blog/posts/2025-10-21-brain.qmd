---
title: "An llm that tweaks itself - Evolutionary based LLM"
description: "An idea on AGI and the human brain"
date: 2025-10-29
categories: [ai, agi, brain]
# image: /me.jpeg
---

> Thinking about the complexity and scale of the problem further, a seemingly inescapable conclusion for me is that we may also need embodiment, and that the only way to build computers that can interpret scenes like we do is to allow them to get exposed to all the years  of (structured, temporally coherent) experience we have,  ability to interact with the world, and some magical active learning/inference architecture that I can barely even imagine when I think backwards about what it should be capable of.

> In any case, we are very, very far and this depresses me. What is the way forward? :( Maybe I should just do a startup. I have a really cool idea for a mobile local social iPhone app. 

- [Andrej Kaparthy | The state of Computer Vision and AI: we are really, really far away. 2012](https://karpathy.github.io/2012/10/22/state-of-computer-vision/)

In the journey of building AGI, we hope to mimic the human brain. 


The core idea is an LLM that can **tweak its own parameters**. An LLM that has **core drivers, motivations, and goals**. 

But that's just the basics, that's a very simplified explainaton of how we humans grow and change.

How we currently interpret our environment is ridiculously complex, beautifully demonstrated in Kaparthy's blog post. We take in so much from our environment. We almost simulate in miniature the thoughts of others,  


but then there's the question of how much does it matter? To accomplish goals and tasks does it need all that. 

Birds and planes ....to create an ai bird we'd consider it's circulatory system, lungs, feathers, wings, etc. It's eyes and the complexity of them... and then we'd consider the complexity of the brain making that in basic terms motivated to survive and knowing how to fly and where in the world its nest resides. 

However if our objective is to make something that flies...a paper plane does the job. 

If our objective is to make people carriers that fly... a plane is still simpler than a bird AND there isn't a single bird on earth that can even carry a person.

So point being... do we really need everything that the human brain has to offer? Or is this just a jumbled mess from natural selection to keep us alive...not the best thinking machines.

I love this particular thing which as an atheist I like to say "The giraffe is proof that God does not exist", I do find these creatures breathtaking to look at, however this laryngeal nerve is a large imperfection.

<iframe width="560" height="315" src="https://www.youtube.com/embed/cO1a1Ek-HD0?si=SfHFzoRT6-TEXZ__" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

> No engineer would ever make a mistake like that

> Remember that a designer, an engineer can go back to the drawing board; throw away the old design, start afresh with what looks more sensible. A designer has foresight. Evolution cannot go back to the drawing board, evolution has no foresight.

- Richard Dawkins

This nerve problem happened due to evolution as the giraffe was once but a small deer that would reach up to eat the leaves of the trees. Overtime the longest necks won out (they could reach the leaves other's could not), and generations later you've got a deer with a ridiculously long neck.

<iframe width="560" height="315" src="https://www.youtube.com/embed/wzIXF6zy7hg?si=BzQazdM-LsD3cnco" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

> The goal of AGI developers is to create an AI model that has the cognitive abilities of a human, including the human brain's ability to reason, learn, and solve a wide range of tasks. 

So perhaps we are always speaing about only the learning part of the brain...not the thinking part.

<iframe width="560" height="315" src="https://www.youtube.com/embed/N1TEjTeQeg0?si=oWmPBFdpjePCopXu" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

[Personal Superintelligence | Mark Zuckerberg](https://www.meta.com/superintelligence/?srsltid=AfmBOoqxUY04XtNRVsgNsdb8YhfiIB42zOFa09_H1mWfKq3gpXuuWw4E)

[Planning for AGI and beyond | OpenAI](https://openai.com/index/planning-for-agi-and-beyond/)

[Taking a responsible path to AGI | DeepMind](https://deepmind.google/discover/blog/taking-a-responsible-path-to-agi/)

Ai as it currently stands can be very easily manipulated

![](https://pbs.twimg.com/media/G2CnBM3acAACtOU)



