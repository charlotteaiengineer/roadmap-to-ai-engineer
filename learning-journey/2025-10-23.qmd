---
title: "Convolutional Neural Networks"
description: ""
date: 2025-10-23
jupyter: python3
categories: [convolutional-neural-networks]
image: /images/owl.png
---

::::: columns
::: {.column width="35%"}
![](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSXmfK3K7hDUDEbs1P0c6esinTf0rKrF5rjmw&s)
:::

::: {.column width="45%"}
[Deep Learning CNN: Convolutional Neural Networks with Python AI Sciences - Published by Packt Publishing](https://learning.oreilly.com/course/deep-learning-cnn/9781803243726/)
:::
:::::

A CNN is for any structural data. Images, Video, Audio, Text, etc.

Colours in digital screens are represented as a combination of Red, Green, and Blue in different intensities. There are three image 'Planes' stacked ontop of eachother.

High spectral images have more stacks ontop of the basic 3. (Geospacial images from satellites for example get height maps too)



```{python}
import numpy as np
import matplotlib.pyplot as plt
im = plt.imread('../images/owl.jpg')
plt.imshow(im)
```

```{python}
im.shape # (height, width, channels)
```

```{python}
R = im[:,:,0]
G = im[:,:,1]
B = im[:,:,2]
plt.imshow(R)
plt.imshow(G)
plt.imshow(B)
plt.axis('off')
```

```{python}
plt.imshow(R, cmap='Reds')
plt.axis('off')
```

```{python}
plt.imshow(R, cmap='gray')
plt.axis('off')
```

```{python}
fig,(ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(10, 15))
ax1.imshow(R, cmap='Reds')
ax1.axis('off')
ax2.imshow(G, cmap='Greens')
ax2.axis('off')
ax3.imshow(B, cmap='Blues')
ax3.axis('off')
plt.show()
```


```{python}
modified_im = im.copy()
modified_im[:,:,2] = 255 # Blue channel
plt.imshow(modified_im)
plt.axis('off')
```



```{python}
modified_im2 = im.copy()
modified_im2[1000:3600,1400:3600,0] = 0 # A position in the image
modified_im2[1000:3600,1400:3600,1] = 255
modified_im2[1000:3600,1400:3600,0] = 0
plt.imshow(modified_im2)    
```


```{python}
grayscale_im = 0.299 * R + 0.587 * G + 0.114 * B # not equal (0.333) values because a more realistic grayscale image would have these values
plt.imshow(grayscale_im, cmap='gray')
plt.axis('off')
```

A filter is a function grid. To blur the image, each pixel is put through an averaging function.
The filter function moves along each pixel, outputting into another image. it takes the average value of the pixels in the filter and applies it to the pixel in the image. 

It takes all the input pixels and multiplies them by the filter values and sums them up to get the output pixel value. This is an image filtering function.

The output image has had convolution applied to it.

# Convolution

![](https://poloclub.github.io/cnn-explainer/assets/figures/convlayer_detailedview_demo.gif)

`Convolutional filter`, `Cross Correlation`

> CNN's take in inputs and produce outputs.

### Edge Detection

Detecting **changes in intensity** across an image. 

We do edge detection when we draw things, we make a thick line around every feature we draw (even though those lines do not exist in real world)


::::: columns
::: {.column width="50%"}
![](https://yolandiehorak.com/wp-content/uploads/2022/07/81b80-img_20180627_163402-11.jpg?w=1000&h=1000)
:::

::: {.column width="50%"}
![](https://i.pinimg.com/736x/fa/5a/1d/fa5a1d989d373689467bdaa4cd387f8e.jpg)
:::
:::::


We even have mathematical rules we have to follow to correctly identify the animal / face for symmetry, proportions, etc.

Image Sharpening is the opposite of blurring where we highlight the changes in intensities of pixel values.

```{python}
import numpy as np
import matplotlib.pyplot as plt
import cv2
from scipy import signal

owl_image = plt.imread('../images/owl.jpg')
grey_owl_image = cv2.cvtColor(owl_image, cv2.COLOR_RGB2GRAY)
plt.imshow(grey_owl_image)
```

> In a Convolutional Neural Network (CNN), a **kernel** (also called a filter) is a small matrix of numbers used to extract features from an input image. This kernel slides over the image, performing element-wise multiplication with the portion of the image it covers, and the sum of these products becomes a new value in an output matrix called a "feature map". By using multiple kernels, a CNN can detect various features like edges, textures, and shapes, which helps the network learn complex pattern

```{python}
kernel_size = 20   
# Increase kernel size to make image more blurry
smoothing_mask = np.ones((kernel_size, kernel_size)) / (kernel_size * kernel_size)
# convolution operation
blurred_owl_image = signal.convolve2d(grey_owl_image, smoothing_mask, boundary='symm', mode='same') 
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 15))
ax1.imshow(grey_owl_image, cmap='gray')
ax2.imshow(blurred_owl_image, cmap='gray') 
# most computationally expensive step, especially when kernel_size is 50 where the blurring is substantial
```


```{python}
x_mask = np.array([[-1, 0, 1], [-1, 0, 1], [-1, 0, 1]])
y_mask = x_mask.T.copy()
fx = signal.convolve2d(grey_owl_image, x_mask, boundary='symm', mode='same')
fy = signal.convolve2d(grey_owl_image, y_mask, boundary='symm', mode='same')
fx.shape
grey_owl_image.shape
```

```{python}
gradient_magnitude = (fx**2 + fy**2)**0.5
plt.imshow(gradient_magnitude, cmap='gray')
```


```{python}
threshold = gradient_magnitude.max()-2*gradient_magnitude.std()
threshold
```

```{python}
 edge = gradient_magnitude > 0.1 # set the threshold to different numbers like 0.1, 0.5...
 plt.imshow(edge, cmap='gray')
```

```{python}
 edge = gradient_magnitude > 10.5 
 plt.imshow(edge, cmap='gray')
```

```{python}
 edge = gradient_magnitude > threshold
 plt.imshow(edge, cmap='gray')
```

```{python}
gradient_magnitude = (fx**2 + fy**2)**0.5
sharp_owl = blurred_owl_image + 5*gradient_magnitude
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 15))
ax1.imshow(blurred_owl_image, cmap='gray')
ax2.imshow(sharp_owl, cmap='gray')
```




## Testing Knowledge

- you must have a function f_conv2d which accepts an image, and a mask. 
- this function returns the convolved image.
- no inbuilt functions for convolution.
- should auto check if image is greyscale or rgb
- should handle both cases
- return image2

```{python}
import numpy as np
import matplotlib.pyplot as plt
# image = plt.imread('../images/anubis.JPG')

# 1. Check if image is greyscale or rgb

# image.shape # this last value tells me 3 layers, so it's rgb
```

```{python}
# if image.shape[2] == 3: # check the channels value
#     print("Image is rgb")
# else:
#     print("Image is greyscale")
```

```{python}
# mask = np.array([[1, 0, 1], [0, 1, 0], [1, 0, 1]])
def f_conv2d(image, mask):
    assert(image.ndim == 2) # Image must be 2D
    assert(mask.ndim == 2) # Mask must be 2D
    # if image.shape[2] == 3:
    #     print("Image is rgb")
    # else:
    #     print("Image is greyscale")
    image_columns = image.shape[1] # number of columns in image
    image_rows = image.shape[0] # number of rows in image
    mask_columns = mask.shape[1] # number of columns in mask saved in this variable
    mask_rows = mask.shape[0] # number of rows in mask

    rows_convolution_will_be_performed_on = image_rows + mask_rows - 1 # subtract 1 because new result after convolution will have one less row and column
    columns_convolution_will_be_performed_on = image_columns + mask_columns - 1 # subtract 1 because new result after convolution will have one less row and column
    Y = np.zeros((rows_convolution_will_be_performed_on, columns_convolution_will_be_performed_on))
    # empty array to store the result of the convolution
    # loop over every row and column in the image
    for m in range(rows_convolution_will_be_performed_on):
        for n in range(columns_convolution_will_be_performed_on):
            for i in range(mask_rows):
                for j in range(mask_columns):
                    #if negative index that cannot exist... checking most things calculatable in the loop
                    if(m-i>0) and (m-i < image_rows) and (n-j>0) and (n-j < image_columns):
                        Y[m,n] = Y[m,n] + mask[i,j] * image[m-i, n-j] # how dot product will be completed
    return Y                    

```

```{python}
mask = np.array([[-1, -2, -1], [0, 0, 0], [1, 2, 1]])
image = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])
```

```{python}
f_conv2d(image, mask) # convolution result
```

# Object Detection

`Object Recognition` - Nothing but the number of object within the image, the number of classes, and the names (convolution at this level)
`Object Localization` - Given an image, identify the objects in the image, find their coordinates and draw a bounding box around them.


I struggled to continue with these lectures, I found the further explainations confusing