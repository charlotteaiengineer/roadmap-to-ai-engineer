{
  "hash": "bb50b0fc2b48935941c555635c51bdf3",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Convolutional Neural Networks\"\ndescription: \"\"\ndate: 2025-10-23\njupyter: python3\ncategories: [convolutional-neural-networks]\nimage: https://www.oreilly.com/covers/urn:orm:video:9781803243726/400w/\n---\n\n::::: columns\n::: {.column width=\"35%\"}\n![](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSXmfK3K7hDUDEbs1P0c6esinTf0rKrF5rjmw&s)\n:::\n\n::: {.column width=\"45%\"}\n[Deep Learning CNN: Convolutional Neural Networks with Python AI Sciences - Published by Packt Publishing](https://learning.oreilly.com/course/deep-learning-cnn/9781803243726/)\n:::\n:::::\n\nA CNN is for any structural data. Images, Video, Audio, Text, etc.\n\nColours in digital screens are represented as a combination of Red, Green, and Blue in different intensities. There are three image 'Planes' stacked ontop of eachother.\n\nHigh spectral images have more stacks ontop of the basic 3. (Geospacial images from satellites for example get height maps too)\n\n::: {#fc82dd4c .cell execution_count=1}\n``` {.python .cell-code}\nimport numpy as np\nimport matplotlib.pyplot as plt\nim = plt.imread('../images/owl.jpg')\nplt.imshow(im)\n```\n\n::: {.cell-output .cell-output-display}\n![](2025-10-23-cnn_files/figure-html/cell-2-output-1.png){width=586 height=394}\n:::\n:::\n\n\n::: {#f0f3f823 .cell execution_count=2}\n``` {.python .cell-code}\nim.shape # (height, width, channels)\n```\n\n::: {.cell-output .cell-output-display execution_count=2}\n```\n(4800, 7200, 3)\n```\n:::\n:::\n\n\n::: {#10d948ae .cell execution_count=3}\n``` {.python .cell-code}\nR = im[:,:,0]\nG = im[:,:,1]\nB = im[:,:,2]\nplt.imshow(R)\nplt.imshow(G)\nplt.imshow(B)\nplt.axis('off')\n```\n\n::: {.cell-output .cell-output-display}\n![](2025-10-23-cnn_files/figure-html/cell-4-output-1.png){width=540 height=366}\n:::\n:::\n\n\n::: {#51d4c145 .cell execution_count=4}\n``` {.python .cell-code}\nplt.imshow(R, cmap='Reds')\nplt.axis('off')\n```\n\n::: {.cell-output .cell-output-display}\n![](2025-10-23-cnn_files/figure-html/cell-5-output-1.png){width=540 height=366}\n:::\n:::\n\n\n::: {#128e267c .cell execution_count=5}\n``` {.python .cell-code}\nplt.imshow(R, cmap='gray')\nplt.axis('off')\n```\n\n::: {.cell-output .cell-output-display}\n![](2025-10-23-cnn_files/figure-html/cell-6-output-1.png){width=540 height=366}\n:::\n:::\n\n\n::: {#823536c7 .cell execution_count=6}\n``` {.python .cell-code}\nfig,(ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(10, 15))\nax1.imshow(R, cmap='Reds')\nax1.axis('off')\nax2.imshow(G, cmap='Greens')\nax2.axis('off')\nax3.imshow(B, cmap='Blues')\nax3.axis('off')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](2025-10-23-cnn_files/figure-html/cell-7-output-1.png){width=763 height=165}\n:::\n:::\n\n\n::: {#4129d50a .cell execution_count=7}\n``` {.python .cell-code}\nmodified_im = im.copy()\nmodified_im[:,:,2] = 255 # Blue channel\nplt.imshow(modified_im)\nplt.axis('off')\n```\n\n::: {.cell-output .cell-output-display}\n![](2025-10-23-cnn_files/figure-html/cell-8-output-1.png){width=540 height=366}\n:::\n:::\n\n\n::: {#ac582e7a .cell execution_count=8}\n``` {.python .cell-code}\nmodified_im2 = im.copy()\nmodified_im2[1000:3600,1400:3600,0] = 0 # A position in the image\nmodified_im2[1000:3600,1400:3600,1] = 255\nmodified_im2[1000:3600,1400:3600,0] = 0\nplt.imshow(modified_im2)    \n```\n\n::: {.cell-output .cell-output-display}\n![](2025-10-23-cnn_files/figure-html/cell-9-output-1.png){width=586 height=394}\n:::\n:::\n\n\n::: {#f0be197e .cell execution_count=9}\n``` {.python .cell-code}\ngrayscale_im = 0.299 * R + 0.587 * G + 0.114 * B # not equal (0.333) values because a more realistic grayscale image would have these values\nplt.imshow(grayscale_im, cmap='gray')\nplt.axis('off')\n```\n\n::: {.cell-output .cell-output-display}\n![](2025-10-23-cnn_files/figure-html/cell-10-output-1.png){width=540 height=366}\n:::\n:::\n\n\nA filter is a function grid. To blur the image, each pixel is put through an averaging function.\nThe filter function moves along each pixel, outputting into another image. it takes the average value of the pixels in the filter and applies it to the pixel in the image. \n\nIt takes all the input pixels and multiplies them by the filter values and sums them up to get the output pixel value. This is an image filtering function.\n\nThe output image has had convolution applied to it.\n\n# Convolution\n\n![](https://poloclub.github.io/cnn-explainer/assets/figures/convlayer_detailedview_demo.gif)\n\n`Convolutional filter`, `Cross Correlation`\n\n> CNN's take in inputs and produce outputs.\n\n### Edge Detection\n\nDetecting **changes in intensity** across an image. \n\nWe do edge detection when we draw things, we make a thick line around every feature we draw (even though those lines do not exist in real world)\n\n\n::::: columns\n::: {.column width=\"50%\"}\n![](https://yolandiehorak.com/wp-content/uploads/2022/07/81b80-img_20180627_163402-11.jpg?w=1000&h=1000)\n:::\n\n::: {.column width=\"50%\"}\n![](https://i.pinimg.com/736x/fa/5a/1d/fa5a1d989d373689467bdaa4cd387f8e.jpg)\n:::\n:::::\n\n\nWe even have mathematical rules we have to follow to correctly identify the animal / face for symmetry, proportions, etc.\n\nImage Sharpening is the opposite of blurring where we highlight the changes in intensities of pixel values.\n\n::: {#6f81b1b8 .cell execution_count=10}\n``` {.python .cell-code}\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport cv2\nfrom scipy import signal\n\nowl_image = plt.imread('../images/owl.jpg')\ngrey_owl_image = cv2.cvtColor(owl_image, cv2.COLOR_RGB2GRAY)\nplt.imshow(grey_owl_image)\n```\n\n::: {.cell-output .cell-output-display}\n![](2025-10-23-cnn_files/figure-html/cell-11-output-1.png){width=586 height=394}\n:::\n:::\n\n\n> In a Convolutional Neural Network (CNN), a **kernel** (also called a filter) is a small matrix of numbers used to extract features from an input image. This kernel slides over the image, performing element-wise multiplication with the portion of the image it covers, and the sum of these products becomes a new value in an output matrix called a \"feature map\". By using multiple kernels, a CNN can detect various features like edges, textures, and shapes, which helps the network learn complex pattern\n\n::: {#5b526817 .cell execution_count=11}\n``` {.python .cell-code}\nkernel_size = 30   # Increase kernel size to make image more blurry\nsmoothing_mask = np.ones((kernel_size, kernel_size)) / (kernel_size * kernel_size)\nim_blurred = signal.convolve2d(grey_owl_image, smoothing_mask, boundary='symm', mode='same') # convolution operation\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 15))\nax1.imshow(grey_owl_image, cmap='gray')\nax2.imshow(im_blurred, cmap='gray')\n```\n\n::: {.cell-output .cell-output-display}\n![](2025-10-23-cnn_files/figure-html/cell-12-output-1.png){width=814 height=272}\n:::\n:::\n\n\n::: {#39121280 .cell execution_count=12}\n``` {.python .cell-code}\nx_mask = np.array([[-1, 0, 1], [-1, 0, 1], [-1, 0, 1]])\ny_mask = x_mask.T.copy()\nfx = signal.convolve2d(grey_owl_image, x_mask, boundary='symm', mode='same')\nfy = signal.convolve2d(grey_owl_image, y_mask, boundary='symm', mode='same')\nfx.shape\ngrey_owl_image.shape\n```\n\n::: {.cell-output .cell-output-display execution_count=12}\n```\n(4800, 7200)\n```\n:::\n:::\n\n\n::: {#7cbb9b34 .cell execution_count=13}\n``` {.python .cell-code}\ngm = (fx**2 + fy**2)**0.5\nplt.imshow(gm, cmap='gray')\n```\n\n::: {.cell-output .cell-output-display}\n![](2025-10-23-cnn_files/figure-html/cell-14-output-1.png){width=586 height=394}\n:::\n:::\n\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/FwFduRA_L6Q?si=8ieLHvWo7Q1cgRpR\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen>\n</iframe>\n\n",
    "supporting": [
      "2025-10-23-cnn_files"
    ],
    "filters": [],
    "includes": {}
  }
}