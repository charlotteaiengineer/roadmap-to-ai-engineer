[
  {
    "objectID": "bookshelf.html",
    "href": "bookshelf.html",
    "title": "Bookshelf",
    "section": "",
    "text": "Welcome to the bookshelf — a curated grid of books and courses I recommend.\n\n  AI Engineering Chip Huyen \n  Practical Guide to Python Nina Zakharenko · Frontend Masters \n    Generative AI with Python & PyTorch (2e) Babcock & Bali · O’Reilly/Packt \n    But how do AI images and videos actually work? Welch Labs"
  },
  {
    "objectID": "learning-journey/week-2025-10-14.html",
    "href": "learning-journey/week-2025-10-14.html",
    "title": "The spelled-out intro to neural networks and backpropagation: building micrograd",
    "section": "",
    "text": "The spelled-out intro to neural networks and backpropagation: building micrograd - by Andrej Karpathy: https://www.youtube.com/watch?v=VMj-3S1tku0"
  },
  {
    "objectID": "learning-journey/week-2025-10-14.html#learning-outcomes",
    "href": "learning-journey/week-2025-10-14.html#learning-outcomes",
    "title": "The spelled-out intro to neural networks and backpropagation: building micrograd",
    "section": "",
    "text": "Explain the difference between discriminative and generative models\nDescribe transformer basics (attention, positional encodings) at a high level\nCompare decoding strategies (greedy vs sampling; top-k intuition)\nApply prompt-engineering fundamentals to steer model outputs\nOutline a minimal LLM app stack (prompting, logging, tooling)"
  },
  {
    "objectID": "learning-journey/week-2025-10-14.html#todays-syllabus",
    "href": "learning-journey/week-2025-10-14.html#todays-syllabus",
    "title": "The spelled-out intro to neural networks and backpropagation: building micrograd",
    "section": "Today’s syllabus",
    "text": "Today’s syllabus\n\nIntroduction to Generative AI (motivation, generative vs discriminative)\nTransformer refresher (attention and positional encoding intuition)\nText generation strategies (greedy vs sampling)\nPrompt engineering fundamentals and safety\nLightweight LLM app scaffolding and tooling overview"
  },
  {
    "objectID": "learning-journey/week-2025-10-14.html#resources",
    "href": "learning-journey/week-2025-10-14.html#resources",
    "title": "The spelled-out intro to neural networks and backpropagation: building micrograd",
    "section": "Resources",
    "text": "Resources\n\nThe spelled-out intro to neural networks and backpropagation: building micrograd\nby Andrej Karpathy: https://www.youtube.com/watch?v=VMj-3S1tku0"
  },
  {
    "objectID": "learning-journey/week-2025-10-14.html#exercises",
    "href": "learning-journey/week-2025-10-14.html#exercises",
    "title": "The spelled-out intro to neural networks and backpropagation: building micrograd",
    "section": "Exercises",
    "text": "Exercises\n\nSummarize generative vs discriminative in 3 sentences with one concrete example of each.\nSketch the data flow of attention for 2 tokens (Q, K, V), labeling shapes.\nImplement a tiny decoder that picks tokens via greedy vs top-k sampling from fake logits."
  },
  {
    "objectID": "learning-journey/week-2025-10-14.html#readiness-checklist",
    "href": "learning-journey/week-2025-10-14.html#readiness-checklist",
    "title": "The spelled-out intro to neural networks and backpropagation: building micrograd",
    "section": "Readiness checklist",
    "text": "Readiness checklist\n\nI can define discriminative vs generative models and give an example of each.\nI can explain attention at a high level and what positional encodings do.\nI can describe greedy vs sampling (and why top-k/top-p exist).\nI can write an effective system and user prompt for a concrete task.\nI can outline components of a minimal LLM app (prompting, logging, tooling)."
  },
  {
    "objectID": "learning-journey/week-2025-10-14.html#examples",
    "href": "learning-journey/week-2025-10-14.html#examples",
    "title": "The spelled-out intro to neural networks and backpropagation: building micrograd",
    "section": "Examples",
    "text": "Examples\n\nGreedy vs sampling with softmax (no external libs)\n\nimport math, random\n\ndef softmax(logits):\n    m = max(logits)\n    exps = [math.exp(x - m) for x in logits]\n    s = sum(exps)\n    return [e / s for e in exps]\n\ndef greedy_sample(logits, vocab):\n    idx = max(range(len(logits)), key=lambda i: logits[i])\n    return vocab[idx]\n\ndef top_k_sample(logits, vocab, k=2):\n    # keep top-k, renormalize, sample\n    idxs = sorted(range(len(logits)), key=lambda i: logits[i], reverse=True)[:k]\n    kept = [logits[i] for i in idxs]\n    probs = softmax(kept)\n    r = random.random()\n    cum = 0.0\n    for i, p in enumerate(probs):\n        cum += p\n        if r &lt;= cum:\n            return vocab[idxs[i]]\n\nvocab = [\"the\", \"a\", \"an\", \"cat\", \"dog\"]\nfake_logits = [1.0, 0.7, 0.2, 0.9, 0.6]  # pretend model scores\n\nprint(\"greedy:\", greedy_sample(fake_logits, vocab))\nprint(\"top-k (k=2):\", [top_k_sample(fake_logits, vocab, k=2) for _ in range(5)])\n\ngreedy: the\ntop-k (k=2): ['the', 'the', 'the', 'the', 'the']\n\n\n\n\nTiny attention intuition with two tokens (toy numbers)\n\n# Two token embeddings (dim=2), toy Q,K,V projections\nimport math\n\nX = [[1.0, 0.0],  # token 1\n     [0.5, 0.5]]  # token 2\n\nW_Q = [[1.0, 0.0],[0.0, 1.0]]\nW_K = [[0.5, 0.5],[0.5, 0.5]]\nW_V = [[1.0, 0.0],[0.0, 1.0]]\n\ndef matmul(A, B):\n    return [[sum(a*b for a, b in zip(row, col)) for col in zip(*B)] for row in A]\n\nQ = matmul(X, W_Q)\nK = matmul(X, W_K)\nV = matmul(X, W_V)\n\ndef dot(a, b):\n    return sum(x*y for x, y in zip(a, b))\n\ndef attention_weights(q_i, K):\n    scores = [dot(q_i, k) for k in K]\n    m = max(scores)\n    exps = [math.exp(s - m) for s in scores]\n    Z = sum(exps)\n    return [e/Z for e in exps]\n\nweights_0 = attention_weights(Q[0], K)\nout_0 = [sum(w*v for w, v in zip(weights_0, col)) for col in zip(*V)]\n\nweights_1 = attention_weights(Q[1], K)\nout_1 = [sum(w*v for w, v in zip(weights_1, col)) for col in zip(*V)]\n\nprint(\"weights token0:\", weights_0)\nprint(\"attended token0:\", out_0)\nprint(\"weights token1:\", weights_1)\nprint(\"attended token1:\", out_1)\n\nweights token0: [0.5, 0.5]\nattended token0: [0.75, 0.25]\nweights token1: [0.5, 0.5]\nattended token1: [0.75, 0.25]\n\n\n\n\nPrompt templating (system + user)\n\ntask = \"Summarize discriminative vs generative models with examples.\"\nsystem = \"You are a precise assistant. Keep answers under 100 words.\"\nuser = f\"Task: {task}\\nConstraints: 3 sentences max.\"\n\nprint(\"SYSTEM:\\n\" + system)\nprint(\"USER:\\n\" + user)\n\nSYSTEM:\nYou are a precise assistant. Keep answers under 100 words.\nUSER:\nTask: Summarize discriminative vs generative models with examples.\nConstraints: 3 sentences max."
  },
  {
    "objectID": "learning-journey/index.html",
    "href": "learning-journey/index.html",
    "title": "Learning Journey",
    "section": "",
    "text": "This is a living, outcome-driven curriculum for becoming an AI Engineer. Each week is a self-contained module with learning outcomes, curated resources, exercises, and a readiness checklist so others can follow along or adapt it to their own path. Open any week below.\n\n\n\n\n\n\n   \n    \n    \n      Order By\n      Default\n      \n        Title\n      \n      \n        Date - Oldest\n      \n      \n        Date - Newest\n      \n    \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nThe spelled-out intro to neural networks and backpropagation: building micrograd\n\n\n\npython\n\npytorch\n\ndeep-learning\n\ngenerative-ai\n\nllm\n\ntransformers\n\n\n\nAndrej Karpathy.\n\n\n\n\n\nOct 14, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nGenerative AI with Python and PyTorch — Second Edition\n\n\n\npython\n\npytorch\n\ndeep-learning\n\ngenerative-ai\n\nllm\n\ntransformers\n\n\n\nStudy outline, exercises, and examples based on Babcock & Bali (O’Reilly, 2025).\n\n\n\n\n\nOct 14, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nPractical Python\n\n\n\npython\n\ndata-structures\n\ntuples\n\nsets\n\ndictionaries\n\nfundamentals\n\n\n\nsets, tuples, dictionaries, mutability & hashing.\n\n\n\n\n\nOct 13, 2025\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "learning-journey/week-2025-10-13.html",
    "href": "learning-journey/week-2025-10-13.html",
    "title": "Practical Python",
    "section": "",
    "text": "Understand how and when to use sets, tuples, and dictionaries\nExplain mutability vs. immutability and implications for hashing\nApply tuple unpacking safely and predictably"
  },
  {
    "objectID": "learning-journey/week-2025-10-13.html#learning-outcomes",
    "href": "learning-journey/week-2025-10-13.html#learning-outcomes",
    "title": "Practical Python",
    "section": "",
    "text": "Understand how and when to use sets, tuples, and dictionaries\nExplain mutability vs. immutability and implications for hashing\nApply tuple unpacking safely and predictably"
  },
  {
    "objectID": "learning-journey/week-2025-10-13.html#key-notes",
    "href": "learning-journey/week-2025-10-13.html#key-notes",
    "title": "Practical Python",
    "section": "Key notes",
    "text": "Key notes\n\nEmpty set literal is set(), not {} (that’s an empty dict).\nSets are unordered, unique collections; you cannot index into a set.\nTuples are immutable; beware stray trailing commas creating tuples unexpectedly.\nTuple unpacking requires counts to match; use _ for values you do not need.\nDictionaries are keyed mappings; use in to check key existence.\nHashable typically implies immutable; lists/dicts/sets are unhashable, tuples/ints/str are hashable."
  },
  {
    "objectID": "learning-journey/week-2025-10-13.html#resources",
    "href": "learning-journey/week-2025-10-13.html#resources",
    "title": "Practical Python",
    "section": "Resources",
    "text": "Resources\n\nFrontend Masters — Practical Guide to Python (full course) by Nina Zakharenko: https://frontendmasters.com/courses/practical-python/"
  },
  {
    "objectID": "learning-journey/week-2025-10-13.html#exercises",
    "href": "learning-journey/week-2025-10-13.html#exercises",
    "title": "Practical Python",
    "section": "Exercises",
    "text": "Exercises\n\nPractice in REPL: construct sets from lists, perform tuple unpacking, and update dicts."
  },
  {
    "objectID": "learning-journey/week-2025-10-13.html#readiness-checklist",
    "href": "learning-journey/week-2025-10-13.html#readiness-checklist",
    "title": "Practical Python",
    "section": "Readiness checklist",
    "text": "Readiness checklist\n\nCan create and manipulate sets, and explain why they are unordered\nCan define tuples and avoid accidental tuple creation via trailing commas\nCan unpack tuples defensively and handle mismatched lengths\nCan use dictionaries idiomatically (membership checks, updates)"
  },
  {
    "objectID": "learning-journey/week-2025-10-13.html#examples",
    "href": "learning-journey/week-2025-10-13.html#examples",
    "title": "Practical Python",
    "section": "Examples",
    "text": "Examples\n\nNumbers and booleans\n\na = 12\nb = 3.5\ntotal = a + b\nis_equal = (a == 2)\ntruthy = True and (1 &lt; 2)\nfalsy = False or (2 &gt; 5)\nnot_val = not False\n\nprint(a, type(a))\nprint(b, type(b))\nprint(total)\nprint(is_equal, truthy, falsy, not_val)\n\n12 &lt;class 'int'&gt;\n3.5 &lt;class 'float'&gt;\n15.5\nFalse True False True\n\n\n\n\nStrings and f-strings\n\nname = \"Charlotte\"\nlang = \"Python\"\nmsg = f\"Hi {name}, welcome to {lang}!\"\n\nprint(name.upper())\nprint(len(name))\nprint(\"thon\" in lang)\nprint(msg)\n\nCHARLOTTE\n9\nTrue\nHi Charlotte, welcome to Python!\n\n\n\n\nLists\n\nnums = [1, 2, 3]\nnums.append(4)\nsliced = nums[1:3]\ndoubled = [x * 2 for x in nums]\n\nprint(nums)\nprint(sliced)\nprint(doubled)\n\n[1, 2, 3, 4]\n[2, 3]\n[2, 4, 6, 8]\n\n\n\n\nTuples\n\nt = (1, \"a\", True)\nsingle = (42,)\npacked = 1, 2  # tuple without parentheses\nx, y = (10, 20)  # unpacking\n\nprint(t)\nprint(single)\nprint(packed)\nprint(x, y)\n\n# t[0] = 99  # TypeError: 'tuple' object does not support item assignment\n\n(1, 'a', True)\n(42,)\n(1, 2)\n10 20\n\n\n\n\nDictionaries\n\nuser = {\"name\": \"Charlotte\", \"role\": \"AI Engineer\"}\nuser[\"city\"] = \"Ipswich\"\n\nprint(user[\"name\"])       # indexing by key\nprint(\"role\" in user)      # membership check on keys\nprint(user)\n\nCharlotte\nTrue\n{'name': 'Charlotte', 'role': 'AI Engineer', 'city': 'Ipswich'}\n\n\n\n\nSets\n\nnames = [\"alice\", \"bob\", \"alice\"]\ns = set(names)\ns.add(\"carol\")\n\nprint(s)\nprint(\"alice\" in s)\n\n{'carol', 'alice', 'bob'}\nTrue\n\n\n\n\nHash function and hashability\n\nprint(hash((\"a\", 1)))  # tuples are hashable if their items are hashable\nprint(hash(\"abc\"))\n\n# hash([1, 2])   # TypeError: unhashable type: 'list'\n# hash({\"k\": 1}) # TypeError: unhashable type: 'dict'\n\n3975176288572512265\n4488045893768172718\n\n\n\n\nLogic: and / or / in\n\nprint(True and False)\nprint(True or False)\nprint(False or 0)\nprint(0 or \"fallback\")\nprint(\"x\" and \"y\")      # returns last truthy operand\nprint(\"py\" in \"python\")  # substring membership\n\nFalse\nTrue\n0\nfallback\ny\nTrue\n\n\n\n\nFunctions\n\ndef my_function(x=4):\n   return x + 2\n\nmy_function()\n\n6\n\n\n\ndef my_other_function(x):\n   return x * 2\n\nmy_other_function(21312)\n\n42624\n\n\n\ndef another_cat(x, y, z=12):\n   return z + (x + y)\n\nanother_cat(1, 2)\n\n15\n\n\n\n\nConditionals\n\ndef my_dogs(x, one, two):\n    if x == 2:\n        return f\"my doggos are {one} and {two}\"\n    elif x &gt; 2:\n        return \"Soon! soon we will have them all!\"\n    else: \n        return \"Got no doggos\"\n\nmy_dogs(1, \"Annie\", \"Anubis\")\n\n'Got no doggos'\n\n\n\ndef fizzbuzz(number):\n    if (number % 3 == 0) and (number % 5 == 0):\n        print(\"fizz\")\n    else: print(\"buzz\")\n\nfizzbuzz(15)\nfizzbuzz(5)\n\nfizz\nbuzz\n\n\n\n\nLoops\n\nfamily = [\"Annie\", \"Anubis\", \"Alex\", \"Charlotte\"]\n\nfor family_member in family:\n    print(f\"My name is {family_member}!\")\n\nprint(f\"outside of the loop {family_member}\")\n\nlist(enumerate(family))\n\nMy name is Annie!\nMy name is Anubis!\nMy name is Alex!\nMy name is Charlotte!\noutside of the loop Charlotte\n\n\n[(0, 'Annie'), (1, 'Anubis'), (2, 'Alex'), (3, 'Charlotte')]\n\n\nenumerate returns list of tuples , first item index, second item the value\n\ncolours = [\"Red\", \"Yellow\", \"Pink\", \"Green\", \"Orange\", \"Purple\", \"Blue\"]\n\nfor index, colour in enumerate(colours):\n    print(f\"this is the greatest colour {colour} number {index}\")\n\nthis is the greatest colour Red number 0\nthis is the greatest colour Yellow number 1\nthis is the greatest colour Pink number 2\nthis is the greatest colour Green number 3\nthis is the greatest colour Orange number 4\nthis is the greatest colour Purple number 5\nthis is the greatest colour Blue number 6\n\n\n\nconcepts_to_learn = {\n    \"Python\": \"Language\",\n    \"TensorFlow\": \"Execution Env\",\n    \"Pytorch\": \"differnt exectuion place\",\n    \"Deep Learning\": \"Neural networks and that\"\n}\n\nfor foo in concepts_to_learn:\n    print(foo)\n\nPython\nTensorFlow\nPytorch\nDeep Learning\n\n\n\nconcepts_to_learn.items()\n\ndict_items([('Python', 'Language'), ('TensorFlow', 'Execution Env'), ('Pytorch', 'differnt exectuion place'), ('Deep Learning', 'Neural networks and that')])\n\n\n\nfor key, value in concepts_to_learn.items():\n    print(key) \n    print(\"----\")\n    print(value)\n\nPython\n----\nLanguage\nTensorFlow\n----\nExecution Env\nPytorch\n----\ndiffernt exectuion place\nDeep Learning\n----\nNeural networks and that\n\n\n\nx = 0\nwhile x &lt; 5:\n    print(x)\n    x += 1\n\n0\n1\n2\n3\n4\n\n\n\nnames = [\"Lisa\", \"Bob\", \"Jeremy\", \"Django\", \"Mario\"]\n\ndef return_target(target=\"Jeremy\"):\n    for name in names:\n        print(name)\n        if name == target:\n            print(f\"we found {target}!\")\n            return name\n\n\n\nList comprehensions\n\nnames = [\"Lisa\", \"Bob\", \"Jeremy\", \"Django\", \"Mario\"]\nmy_list = []\n\nfor name in names:\n    my_list.append(len(name))\n\nprint(\"First way: \", my_list)\n\nprint(\"Shorter way:\", [len(name) for name in names])\n\nFirst way:  [4, 3, 6, 6, 5]\nShorter way: [4, 3, 6, 6, 5]\n\n\n\nnums = [0, 1, 2, 3, 4]\n\n[num * 2 for num in nums] \n\n[0, 2, 4, 6, 8]\n\n\n\n\nSlicing\n\nmy_cake = \"Hey this is a big cake!\"\nmy_cake[14:22]\n\nmy_cake[:18]\nmy_cake[19:]\nmy_cake[-1]\n\n'!'\n\n\n\n\nfiles - reading, writing, appending, and JSON\nBelow are executable examples that will run in this page’s kernel. They demonstrate different open() modes and working with a small JSON file stored alongside this page at learning-journey/data/example.json.\n\n# Write: creates or truncates file\nwith open(\"my_file.txt\", \"w\", encoding=\"utf-8\") as f:\n    f.write(\"first line\\n\")\n    f.write(\"second line\\n\")\n\n# Append: adds to end of file\nwith open(\"my_file.txt\", \"a\", encoding=\"utf-8\") as f:\n    f.write(\"appended line\\n\")\n\n# Read entire file\nwith open(\"my_file.txt\", \"r\", encoding=\"utf-8\") as f:\n    contents = f.read()\ncontents\n\n'first line\\nsecond line\\nappended line\\n'\n\n\n\n# Read line-by-line\nwith open(\"my_file.txt\", \"r\", encoding=\"utf-8\") as f:\n    for line in f:\n        print(line.rstrip())\n\nfirst line\nsecond line\nappended line\n\n\n\n# Explicit open/close (less preferred vs. context manager)\nf = open(\"my_file.txt\", \"r\", encoding=\"utf-8\")\ntry:\n    print(f.readline().rstrip())\nfinally:\n    f.close()\n\nfirst line\n\n\n\n# pathlib usage\nfrom pathlib import Path\n\npath = Path(\"my_file.txt\")\npath.write_text(\"overwritten via pathlib\\n\", encoding=\"utf-8\")\nprint(path.read_text(encoding=\"utf-8\"))\n\noverwritten via pathlib\n\n\n\n\n\nClasses\n\nclass Car:\n    runs = True\n\n    def start(self):\n        if self.runs:\n            print(\"The car starts.\")\n        else:\n            print(\"The car is broken.\")\n\nmy_car = Car()\nmy_car.start()\nmy_car.runs = False\nmy_car.start()\n\nmy_other_car = Car()\nmy_other_car.start()\n\nThe car starts.\nThe car is broken.\nThe car starts.\n\n\n\n\nisinstance\n\nprint(isinstance(my_car, Car))\nprint(isinstance(my_car, str))\nprint(isinstance(\"Hallo there\", str))\nprint(isinstance(12, int))\n\nTrue\nFalse\nTrue\nTrue\n\n\n\n\ninitializing classes\n\nclass Supersupercar:\n    runs = True\n    def __init__(self, make, model, year):\n        self.make = make\n        self.model = model\n        self.year = year\n\n    def start(self):\n        if self.runs:\n            print(f\"The {self.make} {self.model} {self.year} starts.\")\n        else:\n            print(f\"The {self.make} {self.model} {self.year} is broken.\")\n\nmy_car = Supersupercar(\"Toyota\", \"Corolla\", 2020)\nmy_car.start()\n\nmy_better_car = Supersupercar(\"Mustang\", \"GT\", 2025)\nmy_better_car.start()\n\nThe Toyota Corolla 2020 starts.\nThe Mustang GT 2025 starts.\n\n\n\n\n\nMustang GT\n\n\n\n\ninheritance\n\nclass Mustang(Supersupercar):\n    def __init__(self, make, model, year, color):\n        super().__init__(make, model, year)\n        self.color = color\n\nmy_jaguar = Mustang(\"Jaguar\", \"2027\", 2027, \"Green\")\nmy_jaguar.start()\n\nThe Jaguar 2027 2027 starts.\n\n\n\n\n\nJaguar 2027\n\n\n\n\nExceptions\n\ntry:\n    print(10 / 0)\nexcept ZeroDivisionError:\n    print(\"You can't divide by zero!\")\n\ntry:\n    print(10 / 2)\nexcept ValueError:\n    print(\"You can divide by two!\")\n\nYou can't divide by zero!\n5.0\n\n\n\n\nrequests\n\n# import requests\n\n# response = requests.get(\"https://ur-api.....\")\n\n# print(response.status_code)\n# print(response.json())"
  },
  {
    "objectID": "learning-journey/week-2025-10-14-3.html",
    "href": "learning-journey/week-2025-10-14-3.html",
    "title": "Generative AI with Python and PyTorch — Second Edition",
    "section": "",
    "text": "Explain the difference between discriminative and generative models\nDescribe transformer basics (attention, positional encodings) at a high level\nCompare decoding strategies (greedy vs sampling; top-k intuition)\nApply prompt-engineering fundamentals to steer model outputs\nOutline a minimal LLM app stack (prompting, logging, tooling)"
  },
  {
    "objectID": "learning-journey/week-2025-10-14-3.html#learning-outcomes",
    "href": "learning-journey/week-2025-10-14-3.html#learning-outcomes",
    "title": "Generative AI with Python and PyTorch — Second Edition",
    "section": "",
    "text": "Explain the difference between discriminative and generative models\nDescribe transformer basics (attention, positional encodings) at a high level\nCompare decoding strategies (greedy vs sampling; top-k intuition)\nApply prompt-engineering fundamentals to steer model outputs\nOutline a minimal LLM app stack (prompting, logging, tooling)"
  },
  {
    "objectID": "learning-journey/week-2025-10-14-3.html#todays-syllabus",
    "href": "learning-journey/week-2025-10-14-3.html#todays-syllabus",
    "title": "Generative AI with Python and PyTorch — Second Edition",
    "section": "Today’s syllabus",
    "text": "Today’s syllabus\n\nIntroduction to Generative AI (motivation, generative vs discriminative)\nTransformer refresher (attention and positional encoding intuition)\nText generation strategies (greedy vs sampling)\nPrompt engineering fundamentals and safety\nLightweight LLM app scaffolding and tooling overview"
  },
  {
    "objectID": "learning-journey/week-2025-10-14-3.html#resources",
    "href": "learning-journey/week-2025-10-14-3.html#resources",
    "title": "Generative AI with Python and PyTorch — Second Edition",
    "section": "Resources",
    "text": "Resources\n\nGenerative AI with Python and PyTorch — Second Edition, Joseph Babcock & Raghav Bali, 2025: https://learning.oreilly.com/library/view/generative-ai-with/9781835884447/"
  },
  {
    "objectID": "learning-journey/week-2025-10-14-3.html#exercises",
    "href": "learning-journey/week-2025-10-14-3.html#exercises",
    "title": "Generative AI with Python and PyTorch — Second Edition",
    "section": "Exercises",
    "text": "Exercises\n\nSummarize generative vs discriminative in 3 sentences with one concrete example of each.\nSketch the data flow of attention for 2 tokens (Q, K, V), labeling shapes.\nImplement a tiny decoder that picks tokens via greedy vs top-k sampling from fake logits."
  },
  {
    "objectID": "learning-journey/week-2025-10-14-3.html#readiness-checklist",
    "href": "learning-journey/week-2025-10-14-3.html#readiness-checklist",
    "title": "Generative AI with Python and PyTorch — Second Edition",
    "section": "Readiness checklist",
    "text": "Readiness checklist\n\nI can define discriminative vs generative models and give an example of each.\nI can explain attention at a high level and what positional encodings do.\nI can describe greedy vs sampling (and why top-k/top-p exist).\nI can write an effective system and user prompt for a concrete task.\nI can outline components of a minimal LLM app (prompting, logging, tooling)."
  },
  {
    "objectID": "learning-journey/week-2025-10-14-3.html#examples",
    "href": "learning-journey/week-2025-10-14-3.html#examples",
    "title": "Generative AI with Python and PyTorch — Second Edition",
    "section": "Examples",
    "text": "Examples\n\nGreedy vs sampling with softmax (no external libs)\n\nimport math, random\n\ndef softmax(logits):\n    m = max(logits)\n    exps = [math.exp(x - m) for x in logits]\n    s = sum(exps)\n    return [e / s for e in exps]\n\ndef greedy_sample(logits, vocab):\n    idx = max(range(len(logits)), key=lambda i: logits[i])\n    return vocab[idx]\n\ndef top_k_sample(logits, vocab, k=2):\n    # keep top-k, renormalize, sample\n    idxs = sorted(range(len(logits)), key=lambda i: logits[i], reverse=True)[:k]\n    kept = [logits[i] for i in idxs]\n    probs = softmax(kept)\n    r = random.random()\n    cum = 0.0\n    for i, p in enumerate(probs):\n        cum += p\n        if r &lt;= cum:\n            return vocab[idxs[i]]\n\nvocab = [\"the\", \"a\", \"an\", \"cat\", \"dog\"]\nfake_logits = [1.0, 0.7, 0.2, 0.9, 0.6]  # pretend model scores\n\nprint(\"greedy:\", greedy_sample(fake_logits, vocab))\nprint(\"top-k (k=2):\", [top_k_sample(fake_logits, vocab, k=2) for _ in range(5)])\n\ngreedy: the\ntop-k (k=2): ['cat', 'cat', 'the', 'the', 'the']\n\n\n\n\nTiny attention intuition with two tokens (toy numbers)\n\n# Two token embeddings (dim=2), toy Q,K,V projections\nimport math\n\nX = [[1.0, 0.0],  # token 1\n     [0.5, 0.5]]  # token 2\n\nW_Q = [[1.0, 0.0],[0.0, 1.0]]\nW_K = [[0.5, 0.5],[0.5, 0.5]]\nW_V = [[1.0, 0.0],[0.0, 1.0]]\n\ndef matmul(A, B):\n    return [[sum(a*b for a, b in zip(row, col)) for col in zip(*B)] for row in A]\n\nQ = matmul(X, W_Q)\nK = matmul(X, W_K)\nV = matmul(X, W_V)\n\ndef dot(a, b):\n    return sum(x*y for x, y in zip(a, b))\n\ndef attention_weights(q_i, K):\n    scores = [dot(q_i, k) for k in K]\n    m = max(scores)\n    exps = [math.exp(s - m) for s in scores]\n    Z = sum(exps)\n    return [e/Z for e in exps]\n\nweights_0 = attention_weights(Q[0], K)\nout_0 = [sum(w*v for w, v in zip(weights_0, col)) for col in zip(*V)]\n\nweights_1 = attention_weights(Q[1], K)\nout_1 = [sum(w*v for w, v in zip(weights_1, col)) for col in zip(*V)]\n\nprint(\"weights token0:\", weights_0)\nprint(\"attended token0:\", out_0)\nprint(\"weights token1:\", weights_1)\nprint(\"attended token1:\", out_1)\n\nweights token0: [0.5, 0.5]\nattended token0: [0.75, 0.25]\nweights token1: [0.5, 0.5]\nattended token1: [0.75, 0.25]\n\n\n\n\nPrompt templating (system + user)\n\ntask = \"Summarize discriminative vs generative models with examples.\"\nsystem = \"You are a precise assistant. Keep answers under 100 words.\"\nuser = f\"Task: {task}\\nConstraints: 3 sentences max.\"\n\nprint(\"SYSTEM:\\n\" + system)\nprint(\"USER:\\n\" + user)\n\nSYSTEM:\nYou are a precise assistant. Keep answers under 100 words.\nUSER:\nTask: Summarize discriminative vs generative models with examples.\nConstraints: 3 sentences max."
  }
]